# PALMA Docker Compose Configuration
# Full-stack deployment with PostgreSQL, Redis, API, Dashboard, and Workers

version: '3.8'

x-logging: &default-logging
  driver: "json-file"
  options:
    max-size: "10m"
    max-file: "3"

x-environment: &palma-env
  PALMA_CONFIG: /etc/palma/config.yaml
  PALMA_DATA: /var/lib/palma/data
  PALMA_LOGS: /var/log/palma
  DATABASE_URL: postgresql://palma:${POSTGRES_PASSWORD:-changeme}@postgres:5432/palma_db
  REDIS_URL: redis://redis:6379/0
  TZ: UTC

services:
  # ------------------------------
  # PostgreSQL with TimescaleDB
  # ------------------------------
  postgres:
    image: timescale/timescaledb:2.12-pg14
    container_name: palma-postgres
    restart: unless-stopped
    environment:
      POSTGRES_DB: palma_db
      POSTGRES_USER: palma
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-changeme}
      POSTGRES_INITDB_ARGS: "--encoding=UTF8 --locale=C"
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./database/schema.sql:/docker-entrypoint-initdb.d/01-schema.sql
      - ./database/seeds:/docker-entrypoint-initdb.d/seeds
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U palma -d palma_db"]
      interval: 30s
      timeout: 10s
      retries: 5
    logging: *default-logging
    networks:
      - palma-network

  # ------------------------------
  # Redis for caching and message broker
  # ------------------------------
  redis:
    image: redis:7-alpine
    container_name: palma-redis
    restart: unless-stopped
    command: redis-server --appendonly yes --maxmemory 512mb --maxmemory-policy allkeys-lru
    volumes:
      - redis-data:/data
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 5
    logging: *default-logging
    networks:
      - palma-network

  # ------------------------------
  # FastAPI Backend
  # ------------------------------
  api:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: palma-api
    restart: unless-stopped
    environment:
      <<: *palma-env
      PALMA_SERVICE: api
      UVICORN_HOST: 0.0.0.0
      UVICORN_PORT: 8000
      UVICORN_RELOAD: "false"
      UVICORN_WORKERS: 4
    volumes:
      - ./config:/etc/palma:ro
      - palma-data:/var/lib/palma/data
      - palma-logs:/var/log/palma
    ports:
      - "8000:8000"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    command: uvicorn dashboard.api.main:app --host 0.0.0.0 --port 8000 --workers 4
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging: *default-logging
    networks:
      - palma-network

  # ------------------------------
  # Streamlit Dashboard
  # ------------------------------
  dashboard:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: palma-dashboard
    restart: unless-stopped
    environment:
      <<: *palma-env
      PALMA_SERVICE: dashboard
      STREAMLIT_SERVER_PORT: 8501
      STREAMLIT_SERVER_ADDRESS: 0.0.0.0
      STREAMLIT_BROWSER_GATHER_USAGE_STATS: "false"
      API_URL: http://api:8000
    volumes:
      - ./config:/etc/palma:ro
      - palma-data:/var/lib/palma/data
      - palma-logs:/var/log/palma
    ports:
      - "8501:8501"
    depends_on:
      api:
        condition: service_healthy
    command: streamlit run dashboard/app.py --server.port 8501 --server.address 0.0.0.0
    logging: *default-logging
    networks:
      - palma-network

  # ------------------------------
  # Celery Worker (Background Tasks)
  # ------------------------------
  worker:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: palma-worker
    restart: unless-stopped
    environment:
      <<: *palma-env
      PALMA_SERVICE: worker
      CELERY_WORKER_CONCURRENCY: 4
      CELERY_TASK_ALWAYS_EAGER: "false"
    volumes:
      - ./config:/etc/palma:ro
      - palma-data:/var/lib/palma/data
      - palma-logs:/var/log/palma
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    command: celery -A palma.pipeline.celery_app worker --loglevel=info --concurrency=4
    logging: *default-logging
    networks:
      - palma-network

  # ------------------------------
  # Celery Beat (Scheduler)
  # ------------------------------
  beat:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: palma-beat
    restart: unless-stopped
    environment:
      <<: *palma-env
      PALMA_SERVICE: beat
    volumes:
      - ./config:/etc/palma:ro
      - palma-data:/var/lib/palma/data
      - palma-logs:/var/log/palma
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    command: celery -A palma.pipeline.celery_app beat --loglevel=info --scheduler django_celery_beat.schedulers:DatabaseScheduler
    logging: *default-logging
    networks:
      - palma-network

  # ------------------------------
  # Flower (Celery Monitoring)
  # ------------------------------
  flower:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: palma-flower
    restart: unless-stopped
    environment:
      <<: *palma-env
      PALMA_SERVICE: flower
    ports:
      - "5555:5555"
    depends_on:
      redis:
        condition: service_healthy
      worker:
        condition: service_started
    command: celery -A palma.pipeline.celery_app flower --port=5555 --address=0.0.0.0
    logging: *default-logging
    networks:
      - palma-network

  # ------------------------------
  # Nginx Reverse Proxy (Optional)
  # ------------------------------
  nginx:
    image: nginx:alpine
    container_name: palma-nginx
    restart: unless-stopped
    volumes:
      - ./deployment/nginx/palma.conf:/etc/nginx/conf.d/default.conf:ro
      - palma-static:/static
    ports:
      - "80:80"
      - "443:443"
    depends_on:
      - api
      - dashboard
    logging: *default-logging
    networks:
      - palma-network
    profiles:
      - with-proxy

  # ------------------------------
  # Backup Service (Optional)
  # ------------------------------
  backup:
    image: postgres:14-alpine
    container_name: palma-backup
    restart: unless-stopped
    environment:
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-changeme}
    volumes:
      - ./backups:/backups
      - ./scripts/backup.sh:/backup.sh:ro
    entrypoint: |
      sh -c "
      echo '0 2 * * * /backup.sh' > /etc/crontabs/root
      crond -f
      "
    depends_on:
      - postgres
    logging: *default-logging
    networks:
      - palma-network
    profiles:
      - with-backup

# ------------------------------
# Volumes
# ------------------------------
volumes:
  postgres-data:
    driver: local
  redis-data:
    driver: local
  palma-data:
    driver: local
  palma-logs:
    driver: local
  palma-static:
    driver: local

# ------------------------------
# Networks
# ------------------------------
networks:
  palma-network:
    driver: bridge

# ------------------------------
# Usage Examples
# ------------------------------
# Start all services:
#   docker-compose up -d
#
# Start with backup and proxy:
#   docker-compose --profile with-backup --profile with-proxy up -d
#
# Scale workers:
#   docker-compose up -d --scale worker=3
#
# View logs:
#   docker-compose logs -f api
#
# Stop all:
#   docker-compose down
#
# Stop and remove volumes:
#   docker-compose down -v
